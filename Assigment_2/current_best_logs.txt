    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        71.32
    Achieved Active Warps Per SM           warp        45.65
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 28.68%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (71.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    585448.80
    Total DRAM Elapsed Cycles        cycle     55467008
    Average L1 Active Cycles         cycle    838844.28
    Total L1 Elapsed Cycles          cycle    112164368
    Average L2 Active Cycles         cycle    631679.62
    Total L2 Elapsed Cycles          cycle     72219920
    Average SM Active Cycles         cycle    838844.28
    Total SM Elapsed Cycles          cycle    112164368
    Average SMSP Active Cycles       cycle    830364.28
    Total SMSP Elapsed Cycles        cycle    448657472
    -------------------------- ----------- ------------

  BitonicSort_global(int *, int, int, int) (131072, 1, 1)x(1024, 1, 1), Context 1, Stream 13, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         2.62
    SM Frequency                    Ghz         1.60
    Elapsed Cycles                cycle       853237
    Memory Throughput                 %        41.20
    DRAM Throughput                   %        41.20
    Duration                         us       531.90
    L1/TEX Cache Throughput           %        12.08
    L2 Cache Throughput               %        40.06
    SM Active Cycles              cycle    842626.85
    Compute (SM) Throughput           %        52.26
    ----------------------- ----------- ------------

    OPT   This workload exhibits low compute throughput and memory bandwidth utilization relative to the peak           
          performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak           
          typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential       
          reasons.                                                                                                      

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                  1024
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 131072
    Registers Per Thread             register/thread              20
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             132
    Stack Size                                                  1024
    Threads                                   thread       134217728
    # TPCs                                                        66
    Enabled TPC IDs                                              all
    Uses Green Context                                             0
    Waves Per SM                                              496.48
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit Barriers                  block           32
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        71.56
    Achieved Active Warps Per SM           warp        45.80
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 28.44%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (71.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       573937
    Total DRAM Elapsed Cycles        cycle     55717120
    Average L1 Active Cycles         cycle    842626.85
    Total L1 Elapsed Cycles          cycle    112374086
    Average L2 Active Cycles         cycle    653362.41
    Total L2 Elapsed Cycles          cycle     72548000
    Average SM Active Cycles         cycle    842626.85
    Total SM Elapsed Cycles          cycle    112374086
    Average SMSP Active Cycles       cycle    835225.06
    Total SMSP Elapsed Cycles        cycle    449496344
    -------------------------- ----------- ------------

  BitonicSort_global(int *, int, int, int) (131072, 1, 1)x(1024, 1, 1), Context 1, Stream 13, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         2.62
    SM Frequency                    Ghz         1.60
    Elapsed Cycles                cycle       870958
    Memory Throughput                 %        40.37
    DRAM Throughput                   %        40.37
    Duration                         us       542.69
    L1/TEX Cache Throughput           %        11.90
    L2 Cache Throughput               %        39.53
    SM Active Cycles              cycle    852682.70
    Compute (SM) Throughput           %        51.08
    ----------------------- ----------- ------------

    OPT   This workload exhibits low compute throughput and memory bandwidth utilization relative to the peak           
          performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak           
          typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential       
          reasons.                                                                                                      

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                  1024
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 131072
    Registers Per Thread             register/thread              20
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             132
    Stack Size                                                  1024
    Threads                                   thread       134217728
    # TPCs                                                        66
    Enabled TPC IDs                                              all
    Uses Green Context                                             0
    Waves Per SM                                              496.48
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit Barriers                  block           32
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        71.61
    Achieved Active Warps Per SM           warp        45.83
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 28.39%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (71.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    573807.60
    Total DRAM Elapsed Cycles        cycle     56849920
    Average L1 Active Cycles         cycle    852682.70
    Total L1 Elapsed Cycles          cycle    114960072
    Average L2 Active Cycles         cycle    685791.29
    Total L2 Elapsed Cycles          cycle     74002400
    Average SM Active Cycles         cycle    852682.70
    Total SM Elapsed Cycles          cycle    114960072
    Average SMSP Active Cycles       cycle    846825.15
    Total SMSP Elapsed Cycles        cycle    459840288
    -------------------------- ----------- ------------

  BitonicSort_global(int *, int, int, int) (131072, 1, 1)x(1024, 1, 1), Context 1, Stream 13, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         2.62
    SM Frequency                    Ghz         1.60
    Elapsed Cycles                cycle       890926
    Memory Throughput                 %        38.86
    DRAM Throughput                   %        38.86
    Duration                         us       555.20
    L1/TEX Cache Throughput           %        11.60
    L2 Cache Throughput               %        37.78
    SM Active Cycles              cycle    871809.61
    Compute (SM) Throughput           %        49.96
    ----------------------- ----------- ------------

    OPT   This workload exhibits low compute throughput and memory bandwidth utilization relative to the peak           
          performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak           
          typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential       
          reasons.                                                                                                      

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                  1024
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 131072
    Registers Per Thread             register/thread              20
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             132
    Stack Size                                                  1024
    Threads                                   thread       134217728
    # TPCs                                                        66
    Enabled TPC IDs                                              all
    Uses Green Context                                             0
    Waves Per SM                                              496.48
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit Barriers                  block           32
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        71.74
    Achieved Active Warps Per SM           warp        45.91
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 28.26%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (71.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    564934.20
    Total DRAM Elapsed Cycles        cycle     58157952
    Average L1 Active Cycles         cycle    871809.61
    Total L1 Elapsed Cycles          cycle    117554310
    Average L2 Active Cycles         cycle    715018.20
    Total L2 Elapsed Cycles          cycle     75700640
    Average SM Active Cycles         cycle    871809.61
    Total SM Elapsed Cycles          cycle    117554310
    Average SMSP Active Cycles       cycle    858676.34
    Total SMSP Elapsed Cycles        cycle    470217240
    -------------------------- ----------- ------------

  BitonicSort_global(int *, int, int, int) (131072, 1, 1)x(1024, 1, 1), Context 1, Stream 13, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         2.62
    SM Frequency                    Ghz         1.60
    Elapsed Cycles                cycle       808500
    Memory Throughput                 %        41.85
    DRAM Throughput                   %        41.85
    Duration                         us       503.87
    L1/TEX Cache Throughput           %        12.83
    L2 Cache Throughput               %        42.06
    SM Active Cycles              cycle    800048.17
    Compute (SM) Throughput           %        55.05
    ----------------------- ----------- ------------

    OPT   This workload exhibits low compute throughput and memory bandwidth utilization relative to the peak           
          performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak           
          typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential       
          reasons.                                                                                                      

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                  1024
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 131072
    Registers Per Thread             register/thread              20
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             132
    Stack Size                                                  1024
    Threads                                   thread       134217728
    # TPCs                                                        66
    Enabled TPC IDs                                              all
    Uses Green Context                                             0
    Waves Per SM                                              496.48
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit Barriers                  block           32
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        72.31
    Achieved Active Warps Per SM           warp        46.28
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 27.69%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (72.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       552128
    Total DRAM Elapsed Cycles        cycle     52777472
    Average L1 Active Cycles         cycle    800048.17
    Total L1 Elapsed Cycles          cycle    106677212
    Average L2 Active Cycles         cycle    850894.64
    Total L2 Elapsed Cycles          cycle     68813520
    Average SM Active Cycles         cycle    800048.17
    Total SM Elapsed Cycles          cycle    106677212
    Average SMSP Active Cycles       cycle    795025.45
    Total SMSP Elapsed Cycles        cycle    426708848
    -------------------------- ----------- ------------

  BitonicSort_global(int *, int, int, int) (131072, 1, 1)x(1024, 1, 1), Context 1, Stream 13, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         2.62
    SM Frequency                    Ghz         1.60
    Elapsed Cycles                cycle       788374
    Memory Throughput                 %        40.72
    DRAM Throughput                   %        40.72
    Duration                         us       491.30
    L1/TEX Cache Throughput           %        13.14
    L2 Cache Throughput               %        41.51
    SM Active Cycles              cycle    776565.57
    Compute (SM) Throughput           %        56.45
    ----------------------- ----------- ------------

    OPT   This workload exhibits low compute throughput and memory bandwidth utilization relative to the peak           
          performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak           
          typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential       
          reasons.                                                                                                      

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                  1024
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 131072
    Registers Per Thread             register/thread              20
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             132
    Stack Size                                                  1024
    Threads                                   thread       134217728
    # TPCs                                                        66
    Enabled TPC IDs                                              all
    Uses Green Context                                             0
    Waves Per SM                                              496.48
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit Barriers                  block           32
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        73.29
    Achieved Active Warps Per SM           warp        46.90
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 26.71%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (73.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    523834.40
    Total DRAM Elapsed Cycles        cycle     51462912
    Average L1 Active Cycles         cycle    776565.57
    Total L1 Elapsed Cycles          cycle    104039822
    Average L2 Active Cycles         cycle    833588.46
    Total L2 Elapsed Cycles          cycle     67163520
    Average SM Active Cycles         cycle    776565.57
    Total SM Elapsed Cycles          cycle    104039822
    Average SMSP Active Cycles       cycle    770536.44
    Total SMSP Elapsed Cycles        cycle    416159288
    -------------------------- ----------- ------------

  BitonicSort_global(int *, int, int, int) (131072, 1, 1)x(1024, 1, 1), Context 1, Stream 13, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         2.62
    SM Frequency                    Ghz         1.60
    Elapsed Cycles                cycle       779546
    Memory Throughput                 %        37.16
    DRAM Throughput                   %        37.16
    Duration                         us       485.76
    L1/TEX Cache Throughput           %        12.99
    L2 Cache Throughput               %        38.76
    SM Active Cycles              cycle    769926.32
    Compute (SM) Throughput           %        57.08
    ----------------------- ----------- ------------

    OPT   This workload exhibits low compute throughput and memory bandwidth utilization relative to the peak           
          performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak           
          typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential       
          reasons.                                                                                                      

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                  1024
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 131072
    Registers Per Thread             register/thread              20
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             132
    Stack Size                                                  1024
    Threads                                   thread       134217728
    # TPCs                                                        66
    Enabled TPC IDs                                              all
    Uses Green Context                                             0
    Waves Per SM                                              496.48
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit Barriers                  block           32
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        73.25
    Achieved Active Warps Per SM           warp        46.88
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 26.75%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (73.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    472691.20
    Total DRAM Elapsed Cycles        cycle     50886400
    Average L1 Active Cycles         cycle    769926.32
    Total L1 Elapsed Cycles          cycle    102879698
    Average L2 Active Cycles         cycle    823123.53
    Total L2 Elapsed Cycles          cycle     66409440
    Average SM Active Cycles         cycle    769926.32
    Total SM Elapsed Cycles          cycle    102879698
    Average SMSP Active Cycles       cycle    765242.14
    Total SMSP Elapsed Cycles        cycle    411518792
    -------------------------- ----------- ------------

  BitonicSort_global(int *, int, int, int) (131072, 1, 1)x(1024, 1, 1), Context 1, Stream 13, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         2.62
    SM Frequency                    Ghz         1.60
    Elapsed Cycles                cycle       768299
    Memory Throughput                 %        35.64
    DRAM Throughput                   %        35.64
    Duration                         us       478.72
    L1/TEX Cache Throughput           %        13.05
    L2 Cache Throughput               %        37.85
    SM Active Cycles              cycle    757421.87
    Compute (SM) Throughput           %        57.91
    ----------------------- ----------- ------------

    OPT   This workload exhibits low compute throughput and memory bandwidth utilization relative to the peak           
          performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak           
          typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential       
          reasons.                                                                                                      

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                  1024
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 131072
    Registers Per Thread             register/thread              20
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             132
    Stack Size                                                  1024
    Threads                                   thread       134217728
    # TPCs                                                        66
    Enabled TPC IDs                                              all
    Uses Green Context                                             0
    Waves Per SM                                              496.48
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit Barriers                  block           32
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        73.72
    Achieved Active Warps Per SM           warp        47.18
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 26.28%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (73.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    446828.80
    Total DRAM Elapsed Cycles        cycle     50145536
    Average L1 Active Cycles         cycle    757421.87
    Total L1 Elapsed Cycles          cycle    101409632
    Average L2 Active Cycles         cycle    811259.49
    Total L2 Elapsed Cycles          cycle     65451440
    Average SM Active Cycles         cycle    757421.87
    Total SM Elapsed Cycles          cycle    101409632
    Average SMSP Active Cycles       cycle    753342.84
    Total SMSP Elapsed Cycles        cycle    405638528
    -------------------------- ----------- ------------

  BitonicSort_global(int *, int, int, int) (131072, 1, 1)x(1024, 1, 1), Context 1, Stream 13, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         2.62
    SM Frequency                    Ghz         1.60
    Elapsed Cycles                cycle       751115
    Memory Throughput                 %        35.44
    DRAM Throughput                   %        35.44
    Duration                         us       468.06
    L1/TEX Cache Throughput           %        13.33
    L2 Cache Throughput               %        37.83
    SM Active Cycles              cycle    736481.49
    Compute (SM) Throughput           %        59.24
    ----------------------- ----------- ------------

    OPT   This workload exhibits low compute throughput and memory bandwidth utilization relative to the peak           
          performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak           
          typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential       
          reasons.                                                                                                      

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                  1024
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 131072
    Registers Per Thread             register/thread              20
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             132
    Stack Size                                                  1024
    Threads                                   thread       134217728
    # TPCs                                                        66
    Enabled TPC IDs                                              all
    Uses Green Context                                             0
    Waves Per SM                                              496.48
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit Barriers                  block           32
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        74.25
    Achieved Active Warps Per SM           warp        47.52
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 25.75%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (74.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    434416.20
    Total DRAM Elapsed Cycles        cycle     49029504
    Average L1 Active Cycles         cycle    736481.49
    Total L1 Elapsed Cycles          cycle     99125964
    Average L2 Active Cycles         cycle    793098.88
    Total L2 Elapsed Cycles          cycle     63995680
    Average SM Active Cycles         cycle    736481.49
    Total SM Elapsed Cycles          cycle     99125964
    Average SMSP Active Cycles       cycle    728813.68
    Total SMSP Elapsed Cycles        cycle    396503856
    -------------------------- ----------- ------------

  BitonicSort_global(int *, int, int, int) (131072, 1, 1)x(1024, 1, 1), Context 1, Stream 13, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         2.62
    SM Frequency                    Ghz         1.60
    Elapsed Cycles                cycle       748759
    Memory Throughput                 %        35.00
    DRAM Throughput                   %        35.00
    Duration                         us       466.53
    L1/TEX Cache Throughput           %        13.33
    L2 Cache Throughput               %        37.59
    SM Active Cycles              cycle    734088.08
    Compute (SM) Throughput           %        59.42
    ----------------------- ----------- ------------

    OPT   This workload exhibits low compute throughput and memory bandwidth utilization relative to the peak           
          performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak           
          typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential       
          reasons.                                                                                                      

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                  1024
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 131072
    Registers Per Thread             register/thread              20
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             132
    Stack Size                                                  1024
    Threads                                   thread       134217728
    # TPCs                                                        66
    Enabled TPC IDs                                              all
    Uses Green Context                                             0
    Waves Per SM                                              496.48
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit Barriers                  block           32
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        75.01
    Achieved Active Warps Per SM           warp        48.01
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 24.99%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (75.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       427645
    Total DRAM Elapsed Cycles        cycle     48871168
    Average L1 Active Cycles         cycle    734088.08
    Total L1 Elapsed Cycles          cycle     98829232
    Average L2 Active Cycles         cycle    789905.01
    Total L2 Elapsed Cycles          cycle     63790240
    Average SM Active Cycles         cycle    734088.08
    Total SM Elapsed Cycles          cycle     98829232
    Average SMSP Active Cycles       cycle    725699.62
    Total SMSP Elapsed Cycles        cycle    395316928
    -------------------------- ----------- ------------

  BitonicSort_shared_batched_4x(int *, int, int) (32768, 1, 1)x(1024, 1, 1), Context 1, Stream 13, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         2.62
    SM Frequency                    Ghz         1.60
    Elapsed Cycles                cycle      1863145
    Memory Throughput                 %        67.26
    DRAM Throughput                   %        27.01
    Duration                         ms         1.16
    L1/TEX Cache Throughput           %        68.15
    L2 Cache Throughput               %        25.40
    SM Active Cycles              cycle   1838768.96
    Compute (SM) Throughput           %        66.68
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                    1024
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                    32768
    Registers Per Thread             register/thread                26
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             16.38
    Static Shared Memory Per Block        byte/block                 0
    # SMs                                         SM               132
    Stack Size                                                    1024
    Threads                                   thread          33554432
    # TPCs                                                          66
    Enabled TPC IDs                                                all
    Uses Green Context                                               0
    Waves Per SM                                                124.12
    -------------------------------- --------------- -----------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit Barriers                  block           32
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        97.71
    Achieved Active Warps Per SM           warp        62.54
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    821173.20
    Total DRAM Elapsed Cycles        cycle    121609728
    Average L1 Active Cycles         cycle   1838768.96
    Total L1 Elapsed Cycles          cycle    245929462
    Average L2 Active Cycles         cycle   1806423.27
    Total L2 Elapsed Cycles          cycle    158326080
    Average SM Active Cycles         cycle   1838768.96
    Total SM Elapsed Cycles          cycle    245929462
    Average SMSP Active Cycles       cycle   1844566.03
    Total SMSP Elapsed Cycles        cycle    983717848
    -------------------------- ----------- ------------

